{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75124da8",
   "metadata": {},
   "source": [
    "#### Machine Learning Model for Sarcasm Detection \n",
    "\n",
    "This project makes use of the News Headlines dataset, where the dataset will contain the article link, headline and label for the headline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4610f9",
   "metadata": {},
   "source": [
    "#### Data Pre-Processing\n",
    "\n",
    "Loading the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269a22af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "data = pd.read_json(\"dataset/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "data2 = pd.read_json(\"dataset/Sarcasm_Headlines_Dataset_v2.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd41ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, data2])\n",
    "data.drop(['article_link'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90fc01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42392a6",
   "metadata": {},
   "source": [
    "#### Preprocessing data using Tokenization & Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e11701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 19:36:53.652998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41aa5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['headline'])\n",
    "total_words = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f2c1368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "def applyToken(s):\n",
    "    tokens = tokenizer.texts_to_sequences(s)[0]\n",
    "    return tokens\n",
    "\n",
    "data['token'] = [applyToken([x]) for x in data['headline']]\n",
    "max_len = max([len(x) for x in data['token']])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df0313dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     5,  2782,  9018],\n",
       "       [    0,     0,     0, ...,   251,     8,  1081],\n",
       "       [    0,     0,     0, ...,    43,     1, 11426],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     6,   818,  1861],\n",
       "       [    0,     0,     0, ...,  2466,   837,  6340],\n",
       "       [    0,     0,     0, ...,     6,   258,   179]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.array(pad_sequences(data['token'], maxlen = max_len, padding= 'pre'))\n",
    "padded\n",
    "print(len(padded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103e8f1",
   "metadata": {},
   "source": [
    "#### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6761fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = int(0.8* len(padded))\n",
    "X_train = padded[:split_train]\n",
    "X_val = padded[split_train:]\n",
    "Y_train =  data['is_sarcastic'][:split_train]\n",
    "Y_val = data['is_sarcastic'][split_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e35c917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 19:55:19.867158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          494160    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               9600      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 390       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504,157\n",
      "Trainable params: 504,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "2815/2815 [==============================] - 421s 147ms/step - loss: 0.2196 - accuracy: 0.9064 - val_loss: 0.0520 - val_accuracy: 0.9821\n",
      "Epoch 2/5\n",
      "2815/2815 [==============================] - 361s 128ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.0089 - val_accuracy: 0.9970\n",
      "Epoch 3/5\n",
      "2815/2815 [==============================] - 362s 129ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0039 - val_accuracy: 0.9984\n",
      "Epoch 4/5\n",
      "2815/2815 [==============================] - 341s 121ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "2815/2815 [==============================] - 273s 97ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words + 1, 16,),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_train, Y_train, epochs=5, validation_data=(X_val, Y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2debd",
   "metadata": {},
   "source": [
    "#### Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c7baf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f031612",
   "metadata": {},
   "source": [
    "#### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "482beabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "Sarcastic\n"
     ]
    }
   ],
   "source": [
    "s = 'Cows lose their jobs as milk prices drop'\n",
    "tokenizer.fit_on_texts(s)\n",
    "s = tokenizer.texts_to_sequences([s])\n",
    "s = pad_sequences(s, maxlen= max_len, padding='pre')\n",
    "\n",
    "if model.predict(s) >= 0.75:\n",
    "    print(\"Sarcastic\")\n",
    "else:\n",
    "    print(\"Not Sarcastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254cd77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
